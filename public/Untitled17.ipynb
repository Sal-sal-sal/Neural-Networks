{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyN2bBnqYCu1y9C792UEOHqa"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["#\n","#   This program will classify reviews from IMDB based on sentiment, positive or\n","#   negative.  We will used the IMDB database that comes with Keras.\n","#   This data has already preprocessed the reviews.  This preprocessing\n","#   replaces the actual works with the encoding.  So the second most\n","#   popular word is replaced by 2, third most popular by 3, etc.\n","\n","from keras.preprocessing import sequence\n","from keras.models import Sequential\n","from keras.layers import Dense, Embedding, LSTM\n","from keras.callbacks import EarlyStopping\n","from keras.datasets import imdb\n","\n","#   Supress warning and informational messages\n","import os\n","os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n","\n","#   Set parameters for data to use\n","NUM_WORDS = 6000        # the top most n frequent words to consider\n","SKIP_TOP = 2            # Skip the top most words that are likely (the, and, a)\n","MAX_REVIEW_LEN = 100    # Max number of words from a review.\n"],"metadata":{"id":"vMM7Wry-n-VZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#  returns word index vector (ex. [2, 4, 2, 2, 33, 2804, ...]) and class (0 or 1)\n","print(\"encoded word sequence:\", x_train[3], \"class:\", y_train[3])\n","\n","\n","#   Pad and truncate the review word sequences so they are all the same length\n","x_train = sequence.pad_sequences(x_train, maxlen = MAX_REVIEW_LEN)\n","x_test = sequence.pad_sequences(x_test, maxlen = MAX_REVIEW_LEN)\n","print('x_train.shape:', x_train.shape, 'x_test.shape:', x_test.shape)\n","\n","#   The Model\n","model = Sequential()\n","model.add(Embedding(NUM_WORDS, 64 ))\n","model.add(LSTM(64, dropout=0.3, recurrent_dropout=0.3))\n","model.add(Dense(1, activation='sigmoid'))\n","\n","model.compile(loss='binary_crossentropy',\n","            optimizer='adam',\n","            metrics=['accuracy'])\n"],"metadata":{"id":"GBcD9yJZoCZH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","#   Train\n","BATCH_SIZE = 24\n","EPOCHS = 5\n","cbk_early_stopping = EarlyStopping(monitor='val_acc', patience=2, mode='max')\n","model.fit(x_train, y_train, BATCH_SIZE, epochs=EPOCHS,\n","            validation_data=(x_test, y_test),\n","            callbacks=[cbk_early_stopping] )\n","\n","score, acc = model.evaluate(x_test, y_test,\n","                            batch_size=BATCH_SIZE)\n","print('test score:', score, ' test accuracy:', acc)"],"metadata":{"id":"5H3rhgs2oHPz"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5_eYhPbbn7DR","executionInfo":{"status":"ok","timestamp":1737124120171,"user_tz":-300,"elapsed":690827,"user":{"displayName":"Ccg Tru","userId":"12490002955896674145"}},"outputId":"1f7d9588-36f5-4630-f984-7e62b89993b0"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n","\u001b[1m17464789/17464789\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n","encoded word sequence: [2, 4, 2, 2, 33, 2804, 4, 2040, 432, 111, 153, 103, 4, 1494, 13, 70, 131, 67, 11, 61, 2, 744, 35, 3715, 761, 61, 5766, 452, 2, 4, 985, 7, 2, 59, 166, 4, 105, 216, 1239, 41, 1797, 9, 15, 7, 35, 744, 2413, 31, 8, 4, 687, 23, 4, 2, 2, 6, 3693, 42, 38, 39, 121, 59, 456, 10, 10, 7, 265, 12, 575, 111, 153, 159, 59, 16, 1447, 21, 25, 586, 482, 39, 4, 96, 59, 716, 12, 4, 172, 65, 9, 579, 11, 2, 4, 1615, 5, 2, 7, 5168, 17, 13, 2, 12, 19, 6, 464, 31, 314, 11, 2, 6, 719, 605, 11, 8, 202, 27, 310, 4, 3772, 3501, 8, 2722, 58, 10, 10, 537, 2116, 180, 40, 14, 413, 173, 7, 263, 112, 37, 152, 377, 4, 537, 263, 846, 579, 178, 54, 75, 71, 476, 36, 413, 263, 2504, 182, 5, 17, 75, 2306, 922, 36, 279, 131, 2895, 17, 2867, 42, 17, 35, 921, 2, 192, 5, 1219, 3890, 19, 2, 217, 4122, 1710, 537, 2, 1236, 5, 736, 10, 10, 61, 403, 9, 2, 40, 61, 4494, 5, 27, 4494, 159, 90, 263, 2311, 4319, 309, 8, 178, 5, 82, 4319, 4, 65, 15, 2, 145, 143, 5122, 12, 2, 537, 746, 537, 537, 15, 2, 4, 2, 594, 7, 5168, 94, 2, 3987, 2, 11, 2, 4, 538, 7, 1795, 246, 2, 9, 2, 11, 635, 14, 9, 51, 408, 12, 94, 318, 1382, 12, 47, 6, 2683, 936, 5, 2, 2, 19, 49, 7, 4, 1885, 2, 1118, 25, 80, 126, 842, 10, 10, 2, 2, 4726, 27, 4494, 11, 1550, 3633, 159, 27, 341, 29, 2733, 19, 4185, 173, 7, 90, 2, 8, 30, 11, 4, 1784, 86, 1117, 8, 3261, 46, 11, 2, 21, 29, 9, 2841, 23, 4, 1010, 2, 793, 6, 2, 1386, 1830, 10, 10, 246, 50, 9, 6, 2750, 1944, 746, 90, 29, 2, 8, 124, 4, 882, 4, 882, 496, 27, 2, 2213, 537, 121, 127, 1219, 130, 5, 29, 494, 8, 124, 4, 882, 496, 4, 341, 7, 27, 846, 10, 10, 29, 9, 1906, 8, 97, 6, 236, 2, 1311, 8, 4, 2, 7, 31, 7, 2, 91, 2, 3987, 70, 4, 882, 30, 579, 42, 9, 12, 32, 11, 537, 10, 10, 11, 14, 65, 44, 537, 75, 2, 1775, 3353, 2, 1846, 4, 2, 7, 154, 5, 4, 518, 53, 2, 2, 7, 3211, 882, 11, 399, 38, 75, 257, 3807, 19, 2, 17, 29, 456, 4, 65, 7, 27, 205, 113, 10, 10, 2, 4, 2, 2, 9, 242, 4, 91, 1202, 2, 5, 2070, 307, 22, 7, 5168, 126, 93, 40, 2, 13, 188, 1076, 3222, 19, 4, 2, 7, 2348, 537, 23, 53, 537, 21, 82, 40, 2, 13, 2, 14, 280, 13, 219, 4, 2, 431, 758, 859, 4, 953, 1052, 2, 7, 5991, 5, 94, 40, 25, 238, 60, 2, 4, 2, 804, 2, 7, 4, 2, 132, 8, 67, 6, 22, 15, 9, 283, 8, 5168, 14, 31, 9, 242, 955, 48, 25, 279, 2, 23, 12, 1685, 195, 25, 238, 60, 796, 2, 4, 671, 7, 2804, 5, 4, 559, 154, 888, 7, 726, 50, 26, 49, 2, 15, 566, 30, 579, 21, 64, 2574] class: 1\n","x_train.shape: (25000, 100) x_test.shape: (25000, 100)\n","Epoch 1/5\n","\u001b[1m1042/1042\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 97ms/step - accuracy: 0.6929 - loss: 0.5660 - val_accuracy: 0.8327 - val_loss: 0.3824\n","Epoch 2/5\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/callbacks/early_stopping.py:155: UserWarning: Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: accuracy,loss,val_accuracy,val_loss\n","  current = self.get_monitor_value(logs)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m1042/1042\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 80ms/step - accuracy: 0.8438 - loss: 0.3648 - val_accuracy: 0.7382 - val_loss: 0.5513\n","Epoch 3/5\n","\u001b[1m1042/1042\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m147s\u001b[0m 85ms/step - accuracy: 0.8418 - loss: 0.3692 - val_accuracy: 0.8379 - val_loss: 0.3895\n","Epoch 4/5\n","\u001b[1m1042/1042\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 79ms/step - accuracy: 0.8722 - loss: 0.3110 - val_accuracy: 0.8388 - val_loss: 0.3917\n","Epoch 5/5\n","\u001b[1m1042/1042\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 78ms/step - accuracy: 0.8932 - loss: 0.2674 - val_accuracy: 0.8410 - val_loss: 0.3755\n","\u001b[1m1042/1042\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 16ms/step - accuracy: 0.8412 - loss: 0.3809\n","test score: 0.37551558017730713  test accuracy: 0.8410400152206421\n"]}],"source":["#\n","#   This program will classify reviews from IMDB based on sentiment, positive or\n","#   negative.  We will used the IMDB database that comes with Keras.\n","#   This data has already preprocessed the reviews.  This preprocessing\n","#   replaces the actual works with the encoding.  So the second most\n","#   popular word is replaced by 2, third most popular by 3, etc.\n","\n","from keras.preprocessing import sequence\n","from keras.models import Sequential\n","from keras.layers import Dense, Embedding, LSTM\n","from keras.callbacks import EarlyStopping\n","from keras.datasets import imdb\n","\n","#   Supress warning and informational messages\n","import os\n","os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n","\n","#   Set parameters for data to use\n","NUM_WORDS = 6000        # the top most n frequent words to consider\n","SKIP_TOP = 2            # Skip the top most words that are likely (the, and, a)\n","MAX_REVIEW_LEN = 100    # Max number of words from a review.\n","\n","#   Load pre-processed sentiment classified review data from IMDB Database\n","(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words = NUM_WORDS,\n","                                        skip_top=SKIP_TOP)\n","#   Print a sample\n","#  returns word index vector (ex. [2, 4, 2, 2, 33, 2804, ...]) and class (0 or 1)\n","print(\"encoded word sequence:\", x_train[3], \"class:\", y_train[3])\n","\n","\n","#   Pad and truncate the review word sequences so they are all the same length\n","x_train = sequence.pad_sequences(x_train, maxlen = MAX_REVIEW_LEN)\n","x_test = sequence.pad_sequences(x_test, maxlen = MAX_REVIEW_LEN)\n","print('x_train.shape:', x_train.shape, 'x_test.shape:', x_test.shape)\n","\n","#   The Model\n","model = Sequential()\n","model.add(Embedding(NUM_WORDS, 64 ))\n","model.add(LSTM(64, dropout=0.3, recurrent_dropout=0.3))\n","model.add(Dense(1, activation='sigmoid'))\n","\n","#   Compile\n","model.compile(loss='binary_crossentropy',\n","            optimizer='adam',\n","            metrics=['accuracy'])\n","\n","#   Train\n","BATCH_SIZE = 24\n","EPOCHS = 5\n","cbk_early_stopping = EarlyStopping(monitor='val_acc', patience=2, mode='max')\n","model.fit(x_train, y_train, BATCH_SIZE, epochs=EPOCHS,\n","            validation_data=(x_test, y_test),\n","            callbacks=[cbk_early_stopping] )\n","\n","score, acc = model.evaluate(x_test, y_test,\n","                            batch_size=BATCH_SIZE)\n","print('test score:', score, ' test accuracy:', acc)"]},{"cell_type":"code","source":[],"metadata":{"id":"lHqFprkSn8FE"},"execution_count":null,"outputs":[]}]}