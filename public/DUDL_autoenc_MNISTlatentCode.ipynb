{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"19G9gTeBlYPQ-s3VS_3K2bVFtKTP344j6","timestamp":1619266919349},{"file_id":"1FcEBC0NAESIlHQkv6_85R-XDUKGE8XbM","timestamp":1619155961717},{"file_id":"1qKgZ8kVcqNgwtBzHbWq5yJH_HqI6DxWW","timestamp":1617803880910},{"file_id":"15cpyHkJ435B4MqbyGjAH1poN4nCy_DE4","timestamp":1617737766196},{"file_id":"1OLuWuaFu0hcFgkQ2hh5BqbRuqUZD7XcQ","timestamp":1617734878578},{"file_id":"1XvzVGJPTJifVh8OpZVB7ykLxyUqYwQ1j","timestamp":1617196833019},{"file_id":"1bv1_y32e3KEExFKKlPfC3rpw1JxmBr8H","timestamp":1617124341706},{"file_id":"1GMq8u7KyHB2AE7Teyls9gK1T01OduQSn","timestamp":1616697516760},{"file_id":"1Ui3kyHim-e0XLgDs2mkBxVlYg7TKYtcg","timestamp":1616615469755},{"file_id":"1YpHocGI4rApOxIBb1ZghCU5L-hFnv4CK","timestamp":1616608248670}]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"bhWV8oes-wKR"},"source":["# COURSE: A deep understanding of deep learning\n","## SECTION: Autoencoders\n","### LECTURE: The latent code of MNIST\n","#### TEACHER: Mike X Cohen, sincxpress.com\n","##### COURSE URL: udemy.com/course/dudl/?couponCode=202108"]},{"cell_type":"code","metadata":{"id":"YeuAheYyhdZw","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1736407902979,"user_tz":-300,"elapsed":8320,"user":{"displayName":"Ccg Tru","userId":"12490002955896674145"}},"outputId":"b7e18d28-6ab8-47ff-fe2d-3c4c0ec21866"},"source":["# import libraries\n","import numpy as np\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","# NEW! for doing PCA on the model output\n","from sklearn.decomposition import PCA\n","\n","import matplotlib.pyplot as plt\n","from IPython import display\n","display.set_matplotlib_formats('svg')"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-1-05f5a004e356>:13: DeprecationWarning: `set_matplotlib_formats` is deprecated since IPython 7.23, directly use `matplotlib_inline.backend_inline.set_matplotlib_formats()`\n","  display.set_matplotlib_formats('svg')\n"]}]},{"cell_type":"code","source":["!pip install sympy==1.10\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7Jtd62-X-PIr","executionInfo":{"status":"ok","timestamp":1736407912012,"user_tz":-300,"elapsed":9036,"user":{"displayName":"Ccg Tru","userId":"12490002955896674145"}},"outputId":"d4bcc8ab-13e6-4bec-aa18-3a89180ee449"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: sympy==1.10 in /usr/local/lib/python3.10/dist-packages (1.10)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy==1.10) (1.3.0)\n"]}]},{"cell_type":"markdown","metadata":{"id":"0HOkOefftqyg"},"source":["# Import and process the data"]},{"cell_type":"code","metadata":{"id":"MU7rvmWuhjud","executionInfo":{"status":"ok","timestamp":1736407914213,"user_tz":-300,"elapsed":2204,"user":{"displayName":"Ccg Tru","userId":"12490002955896674145"}}},"source":["# import dataset (comes with colab!)\n","data = np.loadtxt(open('sample_data/mnist_train_small.csv','rb'),delimiter=',')\n","\n","# we'll use the labels for matching with the latent code\n","labels = data[:,0]\n","data   = data[:,1:]\n","\n","# normalize the data to a range of [0 1]\n","dataNorm = data / np.max(data)\n","\n","# convert to tensor\n","dataT = torch.tensor( dataNorm ).float()"],"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OK8Opkhgp0bO"},"source":["# Create the DL model"]},{"cell_type":"code","metadata":{"id":"JK3OO3tAtZkA","executionInfo":{"status":"ok","timestamp":1736407914213,"user_tz":-300,"elapsed":3,"user":{"displayName":"Ccg Tru","userId":"12490002955896674145"}}},"source":["# create a class for the model\n","def createTheMNISTAE():\n","\n","  class aenet(nn.Module):\n","    def __init__(self):\n","      super().__init__()\n","\n","      ### input layer\n","      self.input = nn.Linear(784,150)\n","\n","      ### encoder layer\n","      self.enc = nn.Linear(150,15)\n","\n","      ### latent layer\n","      self.lat = nn.Linear(15,150)\n","\n","      ### decoder layer\n","      self.dec = nn.Linear(150,784)\n","\n","    # forward pass\n","    def forward(self,x):\n","      x = F.relu( self.input(x) )\n","\n","      # NEW! output the hidden-layer activation\n","      codex = F.relu( self.enc(x) )\n","\n","      x = F.relu( self.lat(codex) )\n","      y = torch.sigmoid( self.dec(x) )\n","      return y,codex\n","\n","  # create the model instance\n","  net = aenet()\n","\n","  # loss function\n","  lossfun = nn.MSELoss()\n","\n","  # optimizer\n","  optimizer = torch.optim.Adam(net.parameters(),lr=.001)\n","\n","  return net,lossfun,optimizer"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"voQ6mHkfmj1F","colab":{"base_uri":"https://localhost:8080/","height":550},"executionInfo":{"status":"error","timestamp":1736407915217,"user_tz":-300,"elapsed":1006,"user":{"displayName":"Ccg Tru","userId":"12490002955896674145"}},"outputId":"6d2a3562-5be3-415f-cd4c-dddeaa0fd518"},"source":["# test the model with a bit of data\n","net,lossfun,optimizer = createTheMNISTAE()\n","\n","X = dataT[:5,:]\n","yHat = net(X)\n","\n","print('Input shape:')\n","print(X.shape)\n","print(' ')\n","\n","# yHat is now a tuple\n","print(type(yHat),len(yHat))\n","print(' ')\n","\n","print('Shape of model output:')\n","print(yHat[0].shape)\n","print(' ')\n","\n","print('Shape of encoding layer output:')\n","print(yHat[1].shape)"],"execution_count":5,"outputs":[{"output_type":"error","ename":"ImportError","evalue":"cannot import name 'equal_valued' from 'sympy.core.numbers' (/usr/local/lib/python3.10/dist-packages/sympy/core/numbers.py)","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)","\u001b[0;32m<ipython-input-5-d18e59d0202e>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# test the model with a bit of data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlossfun\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreateTheMNISTAE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataT\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0myHat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-4-57ba6265bcd7>\u001b[0m in \u001b[0;36mcreateTheMNISTAE\u001b[0;34m()\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m   \u001b[0;31m# optimizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m   \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m.001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlossfun\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, params, lr, betas, eps, weight_decay, amsgrad, foreach, maximize, capturable, differentiable, fused)\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0mfused\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfused\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         )\n\u001b[0;32m---> 78\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfused\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, params, defaults)\u001b[0m\n\u001b[1;32m    369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mparam_group\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparam_groups\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 371\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_param_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_group\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    372\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m         \u001b[0;31m# Allows _cuda_graph_capture_health_check to rig a poor man's TORCH_WARN_ONCE in python,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_compile.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0mdisable_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"__dynamo_disable\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdisable_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                 \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m                 \u001b[0mdisable_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursive\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_dynamo/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconvert_frame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_frame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresume_execution\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregistry\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlist_backends\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlookup_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregister_backend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcallback\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcallback_handler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon_compile_end\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon_compile_start\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mguards\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGlobalStateGuard\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistributed\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_compile_pg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCompileTimeInstructionCounter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_guards\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcompile_context\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCompileContext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCompileId\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_logging\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mstructured\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_functorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inductor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0minductor_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msymbolic_shapes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pytree\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpytree\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/symbolic_shapes.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_guards\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mShapeGuard\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTracingContext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_python_dispatch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mis_traceable_wrapper_subclass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m from torch.utils._sympy.functions import (\n\u001b[0m\u001b[1;32m     66\u001b[0m     \u001b[0mApplication\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFloorDiv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPythonMod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIsNonOverlappingAndDenseIndicator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCleanDiv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFloorToInt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCeilToInt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/_sympy/functions.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msympy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mApplication\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msympy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogic\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_torf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfuzzy_and\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfuzzy_or\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msympy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumbers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mequal_valued\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msympy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moperations\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLatticeOp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mShortCircuit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msympy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msorting\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mordered\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mImportError\u001b[0m: cannot import name 'equal_valued' from 'sympy.core.numbers' (/usr/local/lib/python3.10/dist-packages/sympy/core/numbers.py)","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"],"errorDetails":{"actions":[{"action":"open_url","actionText":"Open Examples","url":"/notebooks/snippets/importing_libraries.ipynb"}]}}]},{"cell_type":"markdown","metadata":{"id":"dvfGQIRGp0ht"},"source":["# Create a function that trains the model"]},{"cell_type":"code","metadata":{"id":"IblJo1NCp0kl","executionInfo":{"status":"aborted","timestamp":1736407915218,"user_tz":-300,"elapsed":3,"user":{"displayName":"Ccg Tru","userId":"12490002955896674145"}}},"source":["def function2trainTheModel():\n","\n","  # number of epochs\n","  numepochs = 10000\n","\n","  # create a new model\n","  net,lossfun,optimizer = createTheMNISTAE()\n","\n","  # initialize losses\n","  losses = torch.zeros(numepochs)\n","\n","\n","  # loop over epochs\n","  for epochi in range(numepochs):\n","\n","    # select a random set of images\n","    randomidx = np.random.choice(dataT.shape[0],size=32)\n","    X = dataT[randomidx,:]\n","\n","    # forward pass and loss\n","    yHat = net(X)[0] # NEW! here we only care about the final model output\n","    loss = lossfun(yHat,X)\n","\n","    # backprop\n","    optimizer.zero_grad()\n","    loss.backward()\n","    optimizer.step()\n","\n","    # losses in this epoch\n","    losses[epochi] = loss.item()\n","  # end epochs\n","\n","  # function output\n","  return losses,net"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XpGm9xdQ27Ob"},"source":["# Run the model and show the results!"]},{"cell_type":"code","metadata":{"id":"l9pCC1R2p0nu","executionInfo":{"status":"aborted","timestamp":1736407915218,"user_tz":-300,"elapsed":2,"user":{"displayName":"Ccg Tru","userId":"12490002955896674145"}}},"source":["# train the model\n","losses,net = function2trainTheModel()\n","print(f'Final loss: {losses[-1]:.4f}')\n","\n","# visualize the losses\n","plt.plot(losses,'.-')\n","plt.xlabel('Epochs')\n","plt.ylabel('Model loss')\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pG7_3tYbp0wm"},"source":["# Inspect the latent \"code\" of the model"]},{"cell_type":"code","metadata":{"id":"qw56zhmj87WC","executionInfo":{"status":"aborted","timestamp":1736407915218,"user_tz":-300,"elapsed":2,"user":{"displayName":"Ccg Tru","userId":"12490002955896674145"}}},"source":["# output the latent layer\n","\n","# push through the entire dataset\n","yHat,latent = net(dataT)\n","\n","# print sizes\n","print(yHat.shape)\n","print(latent.shape)\n","\n","# what does it look like?\n","fig,ax = plt.subplots(1,2,figsize=(15,5))\n","\n","ax[0].hist(latent.flatten().detach(),100)\n","ax[0].set_xlabel('Latent activation value')\n","ax[0].set_ylabel('Count')\n","ax[0].set_title('Distribution of latent units activations')\n","\n","ax[1].imshow(latent.detach(),aspect='auto',vmin=0,vmax=10)\n","ax[1].set_xlabel('Latent node')\n","ax[1].set_ylabel('Image number')\n","ax[1].set_title('All latent activations')\n","\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9SnUUHPm7xQE","executionInfo":{"status":"aborted","timestamp":1736407915218,"user_tz":-300,"elapsed":2,"user":{"displayName":"Ccg Tru","userId":"12490002955896674145"}}},"source":["# compute the average latent activation for each digit type\n","\n","# initialize output matrix (latent shape by 10 digits)\n","sourcecode = np.zeros((latent.shape[1],10))\n","\n","\n","# loop over digit categories\n","for i in range(10):\n","\n","  # find all pictures of this category\n","  digidx = np.where(labels==i)\n","\n","  # average the latent layer output\n","  sourcecode[:,i] = torch.mean(latent[digidx,:],axis=1).detach()\n","\n","\n","# let's see what it looks like!\n","fig = plt.figure(figsize=(8,5))\n","\n","plt.plot(sourcecode,'s-')\n","plt.legend(range(10),loc=(1.01,.4))\n","plt.xticks(range(15))\n","plt.xlabel('Latent node number')\n","plt.ylabel('Activation')\n","plt.title(\"The model's internal representation of the numbers\")\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RumWkrM82B8N"},"source":["# Explore the reduced-compressed space with PCA"]},{"cell_type":"code","metadata":{"id":"mRrEQMXgrCQj","executionInfo":{"status":"aborted","timestamp":1736407915218,"user_tz":-300,"elapsed":2,"user":{"displayName":"Ccg Tru","userId":"12490002955896674145"}}},"source":["# compute and fit the PCA\n","pcaData = PCA(n_components=15).fit(data) # 15 components to match latent, but it's just to speed computation time\n","pcaCode = PCA(               ).fit(latent.detach())\n","\n","\n","# plot the eigenspectra (scree plot)\n","plt.plot(100*pcaData.explained_variance_ratio_,'s-',label='Data PCA')\n","plt.plot(100*pcaCode.explained_variance_ratio_,'o-',label='Code PCA')\n","plt.xlabel('Components')\n","plt.ylabel('Percent variance explained')\n","plt.title('PCA scree plot')\n","plt.legend()\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9cAVDrS5vbWC","executionInfo":{"status":"aborted","timestamp":1736407915219,"user_tz":-300,"elapsed":3,"user":{"displayName":"Ccg Tru","userId":"12490002955896674145"}}},"source":["# compute the projection of the data onto the PC axes\n","scoresData = pcaData.fit_transform(data)\n","scoresCode = pcaCode.fit_transform(latent.detach())\n","\n","# plot the data separately per number\n","fig,ax = plt.subplots(1,2,figsize=(15,5))\n","\n","for lab in range(10):\n","  ax[0].plot(scoresData[labels==lab,0],scoresData[labels==lab,1],'o',markersize=3,alpha=.4)\n","  ax[1].plot(scoresCode[labels==lab,0],scoresCode[labels==lab,1],'o',markersize=3,alpha=.4)\n","\n","for i in range(2):\n","  ax[i].set_xlabel('PC1 projection')\n","  ax[i].set_ylabel('PC2 projection')\n","  ax[i].legend(range(10))\n","\n","ax[0].set_title('PCA of data')\n","ax[1].set_title('PCA of latent code')\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3vB1b_MGBlVv","executionInfo":{"status":"aborted","timestamp":1736407915219,"user_tz":-300,"elapsed":3,"user":{"displayName":"Ccg Tru","userId":"12490002955896674145"}}},"source":["# This cell is not important! It's just the code I used to make the figure in the slide. I decided to leave it here FYI.\n","\n","fig,ax = plt.subplots(1,3,figsize=(15,3))\n","\n","ax[0].imshow(dataT[0,:].view(28,28),cmap='gray')\n","\n","ax[1].plot(dataT[0,:],'ks')\n","ax[1].set_xlabel('Pixels (vectorized)')\n","ax[1].set_ylabel('Intensity value')\n","\n","ax[2].plot(latent[0,:].detach(),'ks')\n","ax[2].set_xlabel('Latent units')\n","ax[2].set_ylabel('Activation (a.u.)')\n","\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nlmKG35AVGJp","executionInfo":{"status":"aborted","timestamp":1736407047818,"user_tz":-300,"elapsed":3,"user":{"displayName":"Ccg Tru","userId":"12490002955896674145"}}},"source":[],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Uh28k_l29urR"},"source":["# Additional explorations"]},{"cell_type":"code","metadata":{"id":"ib3uQtfv9wE2","executionInfo":{"status":"aborted","timestamp":1736407047818,"user_tz":-300,"elapsed":3,"user":{"displayName":"Ccg Tru","userId":"12490002955896674145"}}},"source":["# 1) Are you surprised that the latent activations (e.g., from the histogram) are all non-negative? Is that because of\n","#    the image normalization, or what is causing those values to be all non-negative?\n","#\n","# 2) Averages don't tell the whole story. Redraw the \"Model's internal representation\" line plot but using standard\n","#    deviation instead of mean. This graph will tell you if any numbers, or units, have particularly higher variability\n","#    than others. Is this the case, and does the std plot give you any more insight into the model's learned representation?\n","#\n","# 3) The PC-space plots are tricky to interpret: This is a 15-dimensional space but 13 dimensions are projected onto two.\n","#    It's possible that the numbers are better separated in other dimensions, just like a 2D photograph of someone standing\n","#    behind a tree makes them inseparable whereas they are separable in the original 3D space. Modify the plot to show\n","#    PC dimensions 2&3 instead of 1&2.\n","#"],"execution_count":null,"outputs":[]}]}