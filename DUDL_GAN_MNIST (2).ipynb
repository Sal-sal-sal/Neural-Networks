{"cells":[{"cell_type":"markdown","metadata":{"id":"bhWV8oes-wKR"},"source":["# COURSE: A deep understanding of deep learning\n","## SECTION: Generative adversarial networks\n","### LECTURE: Linear GAN with MNIST\n","#### TEACHER: Mike X Cohen, sincxpress.com\n","##### COURSE URL: udemy.com/course/dudl/?couponCode=202108"]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":312,"status":"ok","timestamp":1736850517486,"user":{"displayName":"Cal Cal","userId":"03819414586018809751"},"user_tz":-300},"id":"YeuAheYyhdZw","outputId":"dfa1522c-fca6-4182-9ca2-30920316fc38"},"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-17-a4fab4827556>:12: DeprecationWarning: `set_matplotlib_formats` is deprecated since IPython 7.23, directly use `matplotlib_inline.backend_inline.set_matplotlib_formats()`\n","  display.set_matplotlib_formats('svg')\n"]}],"source":["# import libraries\n","import numpy as np\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","import sys\n","\n","import matplotlib.pyplot as plt\n","from IPython import display\n","display.set_matplotlib_formats('svg')\n","import torchvision as tv"]},{"cell_type":"code","execution_count":18,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1736850517826,"user":{"displayName":"Cal Cal","userId":"03819414586018809751"},"user_tz":-300},"id":"Kq6NnCWpxti5"},"outputs":[],"source":["datac = tv.datasets.FashionMNIST(root = '/data', train= True,download=True)\n","datac.classes\n","datac.targets\n","labels = np.array(datac.targets)\n","datac1=np.array(datac.data)\n","# 1,2,5,7"]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1736850517826,"user":{"displayName":"Cal Cal","userId":"03819414586018809751"},"user_tz":-300},"id":"lpcmh-V8hIlw","outputId":"0651004f-d1ee-4351-d5ef-d5b211591eca"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(60000, 28, 28)"]},"metadata":{},"execution_count":19}],"source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","datac1.shape"]},{"cell_type":"markdown","metadata":{"id":"vpUeQWVfBJbY"},"source":["# Import the data"]},{"cell_type":"code","execution_count":20,"metadata":{"executionInfo":{"elapsed":288,"status":"ok","timestamp":1736850518112,"user":{"displayName":"Cal Cal","userId":"03819414586018809751"},"user_tz":-300},"id":"9yieClqXzeum"},"outputs":[],"source":["\n","data = datac1[np.where((labels == 1)| (labels ==2) | (labels == 5)| (labels ==7))]\n","data = data.reshape(data.shape[0],data.shape[-2]**2)"]},{"cell_type":"code","execution_count":21,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1736850518112,"user":{"displayName":"Cal Cal","userId":"03819414586018809751"},"user_tz":-300},"id":"yfZKI3EXBHL5","outputId":"07bfbd78-a412-4209-8f1b-e0782faa0062"},"outputs":[{"output_type":"stream","name":"stdout","text":["(24000, 784)\n"]}],"source":["# import dataset (comes with colab!)\n","\n","\n","\n","\n","# tar = []\n","# data = np.loadtxt(open('sample_data/mnist_train_small.csv','rb'),delimiter=',')\n","\n","# don't need the labels here\n","# data = data[:,1:]\n","print(data.shape)\n","# normalize the data to a range of [-1 1] (b/c tanh output)\n","dataNorm = data / np.max(data)\n","dataNorm = 2*dataNorm - 1\n","\n","# convert to tensor\n","dataT = torch.tensor( dataNorm ).float()\n","\n","# no dataloaders!\n","batchsize = 100\n"]},{"cell_type":"markdown","metadata":{"id":"7vvglaJyCMpO"},"source":["# Create classes for the discriminator and generator"]},{"cell_type":"code","execution_count":22,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":351},"executionInfo":{"elapsed":296,"status":"error","timestamp":1736850518407,"user":{"displayName":"Cal Cal","userId":"03819414586018809751"},"user_tz":-300},"id":"UT-TyZZDK9-9","outputId":"c0bc6ddb-1618-4a63-da29-1aa4a3fe5c7f"},"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument mat1 in method wrapper_CUDA_addmm)","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-22-2b5e660c767e>\u001b[0m in \u001b[0;36m<cell line: 18>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# print(X[0].shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mdnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdiscriminatorNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-22-2b5e660c767e>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaky_relu\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaky_relu\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument mat1 in method wrapper_CUDA_addmm)"]}],"source":["class discriminatorNet(nn.Module):\n","  def __init__(self):\n","    super().__init__()\n","\n","    self.fc1 = nn.Linear(28*28,256)\n","    self.fc2 = nn.Linear(256,256)\n","    self.out = nn.Linear(256,1)\n","\n","  def forward(self,x):\n","    x = F.leaky_relu( self.fc1(x) )\n","    x = F.leaky_relu( self.fc2(x) )\n","    x = self.out(x)\n","    return torch.sigmoid( x )\n","\n","# X = next(iter(dataload))\n","# print(X[0].shape)\n","dnet = discriminatorNet()\n","y = dnet(X[0])\n","y"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":7,"status":"aborted","timestamp":1736850518408,"user":{"displayName":"Cal Cal","userId":"03819414586018809751"},"user_tz":-300},"id":"alVVPOJiLTHB"},"outputs":[],"source":["class generatorNet(nn.Module):\n","  def __init__(self):\n","    super().__init__()\n","\n","    self.fc1 = nn.Linear(64,256)\n","    self.fc2 = nn.Linear(256,256)\n","    self.out = nn.Linear(256,784)\n","\n","  def forward(self,x):\n","    x = F.leaky_relu( self.fc1(x) )\n","    x = F.leaky_relu( self.fc2(x) )\n","    x = self.out(x)\n","    return torch.tanh( x )\n","\n","\n","gnet = generatorNet()\n","y = gnet(torch.randn(10,64))\n","c = dnet(y)\n","\n","plt.imshow(y[0,:].detach().squeeze().view(28,28));"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":6,"status":"aborted","timestamp":1736850518408,"user":{"displayName":"Cal Cal","userId":"03819414586018809751"},"user_tz":-300},"id":"rH_IB8oi1M7q"},"outputs":[],"source":["data.shape"]},{"cell_type":"markdown","metadata":{"id":"bBsOOqcX_LvO"},"source":["# Train the models!"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":6,"status":"aborted","timestamp":1736850518408,"user":{"displayName":"Cal Cal","userId":"03819414586018809751"},"user_tz":-300},"id":"SFDbnRqeCPqy"},"outputs":[],"source":["# loss function (same for both phases of training)\n","lossfun = nn.BCELoss()\n","\n","# create instances of the models\n","dnet = discriminatorNet().to(device)\n","gnet = generatorNet().to(device)\n","\n","# optimizers (same algo but different variables b/c different parameters)\n","d_optimizer = torch.optim.Adam(dnet.parameters(), lr=.0003)\n","g_optimizer = torch.optim.Adam(gnet.parameters(), lr=.0003)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TQs0MVfW7Ecw","executionInfo":{"status":"aborted","timestamp":1736850518408,"user_tz":-300,"elapsed":6,"user":{"displayName":"Cal Cal","userId":"03819414586018809751"}}},"outputs":[],"source":["td = torch.utils.data.TensorDataset(dataT)\n","dataload = torch.utils.data.DataLoader(td,batch_size=batchsize)"]},{"cell_type":"code","source":[],"metadata":{"id":"wOUhRcIY95b_","executionInfo":{"status":"aborted","timestamp":1736850518408,"user_tz":-300,"elapsed":6,"user":{"displayName":"Cal Cal","userId":"03819414586018809751"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LIkXltv_7NuK","executionInfo":{"status":"aborted","timestamp":1736850518408,"user_tz":-300,"elapsed":6,"user":{"displayName":"Cal Cal","userId":"03819414586018809751"}}},"outputs":[],"source":["def smooth(dat):\n","  for i in range(3,len(data)):\n","    dat[i]= dat[i]*0.7 + data[i-1]*0.3"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"83Ju8fDuUTBg","executionInfo":{"status":"aborted","timestamp":1736850518408,"user_tz":-300,"elapsed":6,"user":{"displayName":"Cal Cal","userId":"03819414586018809751"}}},"outputs":[],"source":["# this cell takes ~3 mins with 50k epochs\n","num_epochs = 20\n","\n","losses  = np.zeros((num_epochs,2))\n","disDecs = np.zeros((num_epochs,2)) # disDecs = discriminator decisions\n","\n","for epochi in range(num_epochs):\n","  for X in dataload:\n","    X = X[0].to(device)\n","  # create minibatches of REAL and FAKE images\n","\n","    real_images = X.to(device)\n","    fake_images = gnet( torch.randn(batchsize,64).to(device) ) # output of generator\n","\n","\n","    # labels used for real and fake images\n","    real_labels = torch.ones(batchsize,1).to(device)\n","    fake_labels = torch.zeros(batchsize,1).to(device)\n","\n","\n","\n","    ### ---------------- Train the discriminator ---------------- ###\n","\n","    # forward pass and loss for REAL pictures\n","    pred_real   = dnet(real_images)              # REAL images into discriminator\n","    d_loss_real = lossfun(pred_real,real_labels) # all labels are 1\n","\n","    # forward pass and loss for FAKE pictures\n","    pred_fake   = dnet(fake_images)              # FAKE images into discriminator\n","    d_loss_fake = lossfun(pred_fake,fake_labels) # all labels are 0\n","\n","    # collect loss (using combined losses)\n","    d_loss = d_loss_real + d_loss_fake\n","    losses[epochi,0]  = d_loss.item()\n","    disDecs[epochi,0] = torch.mean((pred_real>.5).float()).detach()\n","\n","    # backprop\n","    d_optimizer.zero_grad()\n","    d_loss.backward()\n","    d_optimizer.step()\n","\n","\n","\n","\n","    ### ---------------- Train the generator ---------------- ###\n","\n","    # create fake images and compute loss\n","    fake_images = gnet( torch.randn(batchsize,64).to(device) )\n","    pred_fake   = dnet(fake_images)\n","\n","    # compute and collect loss and accuracy\n","    g_loss = lossfun(pred_fake,real_labels)\n","    losses[epochi,1]  = g_loss.item()\n","    disDecs[epochi,1] = torch.mean((pred_fake>.5).float()).detach()\n","\n","    # backprop\n","    g_optimizer.zero_grad()\n","    g_loss.backward()\n","    g_optimizer.step()\n","\n","\n","    # print out a status message\n","\n","    msg = f'Finished epoch {epochi+1}/{num_epochs}'\n","    sys.stdout.write('\\r' + msg)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1C0qAf9kN7mi","executionInfo":{"status":"aborted","timestamp":1736850518408,"user_tz":-300,"elapsed":6,"user":{"displayName":"Cal Cal","userId":"03819414586018809751"}}},"outputs":[],"source":["fig,ax = plt.subplots(1,3,figsize=(18,5))\n","los = smooth(losses)\n","ax[0].plot(losses)\n","ax[0].set_xlabel('Epochs')\n","ax[0].set_ylabel('Loss')\n","ax[0].set_title('Model loss')\n","ax[0].legend(['Discrimator','Generator'])\n","# ax[0].set_xlim([4000,5000])\n","\n","ax[1].plot(losses.reshape(-1),losses.reshape(-1),'k.',alpha=.1)\n","ax[1].set_xlabel('Discriminator loss')\n","ax[1].set_ylabel('Generator loss')\n","\n","ax[2].plot(disDecs)\n","ax[2].set_xlabel('Epochs')\n","ax[2].set_ylabel('Probablity (\"real\")')\n","ax[2].set_title('Discriminator output')\n","ax[2].legend(['Real','Fake'])\n","\n","plt.show()"]},{"cell_type":"code","source":["disDecs"],"metadata":{"id":"sTSeV-pTJivV","executionInfo":{"status":"aborted","timestamp":1736850518408,"user_tz":-300,"elapsed":6,"user":{"displayName":"Cal Cal","userId":"03819414586018809751"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ElnXz0ZkS8Yc"},"source":["# Let's see some fake digits!"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":5,"status":"aborted","timestamp":1736850518408,"user":{"displayName":"Cal Cal","userId":"03819414586018809751"},"user_tz":-300},"id":"AzCz1UqGCP8T"},"outputs":[],"source":["# generate the images from the generator network\n","gnet.eval()\n","fake_data = gnet(torch.randn(12,64).to(device)).cpu()\n","\n","# and visualize...\n","fig,axs = plt.subplots(3,4,figsize=(8,6))\n","for i,ax in enumerate(axs.flatten()):\n","  ax.imshow(fake_data[i,:,].detach().view(28,28),cmap='gray')\n","  ax.axis('off')\n","\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":5,"status":"aborted","timestamp":1736850518408,"user":{"displayName":"Cal Cal","userId":"03819414586018809751"},"user_tz":-300},"id":"vraFRebko51H"},"outputs":[],"source":["fig,axs = plt.subplots(2.10,figsize=(8,6))\n","for i,ax in enumerate(axs.flatten()):\n","  ax.imshow(.detach().view(28,28),cmap='gray')\n","  ax.axis('off')\n","\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":5,"status":"aborted","timestamp":1736850518408,"user":{"displayName":"Cal Cal","userId":"03819414586018809751"},"user_tz":-300},"id":"pU-I5tvmCP-6"},"outputs":[],"source":["lis_fimg"]},{"cell_type":"markdown","metadata":{"id":"-Q1Cx6X9i0H-"},"source":["# Additional explorations"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":5,"status":"aborted","timestamp":1736850518408,"user":{"displayName":"Cal Cal","userId":"03819414586018809751"},"user_tz":-300},"id":"IfVbtROJi0K2"},"outputs":[],"source":["# 1) I tried adding batch normalization to the models, but the results weren't that nice. Can you guess why? Try adding\n","#    batchnorm after each layer (except the output) and observe the effects. Can you explain why the results are the\n","#    way they are? (Note: batchnorm becomes important in deeper CNN GANs.)\n","#\n","# 2) Re-running the same code to show the fake images returns different digits each time. Fix PyTorch's random seed so\n","#    that the random numbers are identical each time you run the code. Are the images still different on multiple runs?\n","#\n","# 3) To see how the generator is progressing, you can create some images during training. Here's what to do: (1) put the\n","#    image-generation code above inside a function. (2) Modify that function so that the figure is saved to a file.\n","#    (3) Modify the training function so that it calls the plotting function every 5000 epochs (or whatever resolution\n","#    you want). Then you can see how the images look more like digits as the generator model learns!\n","#\n","# 4) GANs can be quite sensitive to the learning rate, because you are training two different but interacting networks\n","#    at the same time. Usually a good strategy is to have a very small learning rate and train for a long time. But don't\n","#    take my advice -- try a much larger learning rate for a shorter period of time, and see what happens!\n","#"]},{"cell_type":"code","source":[],"metadata":{"id":"KT-QpL6NG87c","executionInfo":{"status":"aborted","timestamp":1736850518409,"user_tz":-300,"elapsed":6,"user":{"displayName":"Cal Cal","userId":"03819414586018809751"}}},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[{"file_id":"1W9fGz1EYzDhtHHpBYU6M2fEpi9Q1uXez","timestamp":1620754493662}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}